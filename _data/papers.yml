papers:
  -
    cite: 2022TIP_an_selfsupervise
    type: engineering
    topic: retinal_alignment
    title: Self-Supervised Rigid Registration for Multimodal Retinal Images
    authors: Cheolhong An, Yiqian Wang, Junkang Zhang, Truong Q. Nguyen
    journal: IEEE Transactions on Image Processing
    year: 2022
    doi: https://doi.org/10.1109/TIP.2022.3201476

    image_bar: /images/bar_TIP2022_selfsupervise.png

    abstract: The ability to accurately overlay one modality retinal image to another is critical in ophthalmology. Our previous framework achieved the state-of-the-art results for multimodal retinal image registration. However, it requires human-annotated labels due to the supervised approach of the previous work. In this paper, we propose a self-supervised multimodal retina registration method to alleviate the burdens of time and expense to prepare for training data, that is, aiming to automatically register multimodal retinal images without any human annotations. Specially, we focus on registering color fundus images with infrared reflectance and fluorescein angiography images, and compare registration results with several conventional and supervised and unsupervised deep learning methods. From the experimental results, the proposed self-supervised framework achieves a comparable accuracy comparing to the state-of-the-art supervised learning method in terms of registration accuracy and Dice coefficient.

  -
    cite: 2022TIP_zhang_twostep
    type: engineering
    topic: retinal_alignment
    title: Two-Step Registration on Multi-Modal Retinal Images via Deep Neural Networks
    authors: Junkang Zhang, Yiqian Wang, Ji Dai, Melina Cavichini, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen, Cheolhong An
    journal: IEEE Transactions on Image Processing
    year: 2022
    doi: https://doi.org/10.1109/TIP.2021.3135708

    image_bar: /images/bar_TIP2022_twostep.png

    abstract: Multi-modal retinal image registration plays an important role in the ophthalmological diagnosis process. The conventional methods lack robustness in aligning multi-modal images of various imaging qualities. Deep-learning methods have not been widely developed for this task, especially for the coarse-to-fine registration pipeline. To handle this task, we propose a two-step method based on deep convolutional networks, including a coarse alignment step and a fine alignment step. In the coarse alignment step, a global registration matrix is estimated by three sequentially connected networks for vessel segmentation, feature detection and description, and outlier rejection, respectively. In the fine alignment step, a deformable registration network is set up to find pixel-wise correspondence between a target image and a coarsely aligned image from the previous step to further improve the alignment accuracy. Particularly, an unsupervised learning framework is proposed to handle the difficulties of inconsistent modalities and lack of labeled training data for the fine alignment step. The proposed framework first changes multi-modal images into a same modality through modality transformers, and then adopts photometric consistency loss and smoothness loss to train the deformable registration network. The experimental results show that the proposed method achieves state-of-the-art results in Dice metrics and is more robust in challenging cases.

  -
    cite: 2021TIP_wang_robust
    type: engineering
    topic: retinal_alignment
    title: Robust content-adaptive global registration for multimodal retinal images using weakly supervised deep-learning framework
    authors: Yiqian Wang, Junkang Zhang, Melina Cavichini, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen, Cheolhong An
    journal: IEEE Transactions on Image Processing
    year: 2021
    doi: https://doi.org/10.1109/TIP.2021.3058570

    image_bar: /images/bar_TIP2021_robust.png

    abstract: Multimodal retinal imaging plays an important role in ophthalmology. We propose a content-adaptive multimodal retinal image registration method in this paper that focuses on the globally coarse alignment and includes three weakly supervised neural networks for vessel segmentation, feature detection and description, and outlier rejection. We apply the proposed framework to register color fundus images with infrared reflectance and fluorescein angiography images, and compare it with several conventional and deep learning methods. Our proposed framework demonstrates a significant improvement in robustness and accuracy reflected by a higher success rate and Dice coefficient compared with other methods.

  -
    cite: 2020IEEEaccess_wang_metriccorrelation
    type: engineering
    topic: retinal_alignment
    title: Study on Correlation Between Subjective and Objective Metrics for Multimodal Retinal Image Registration
    authors: Yiqian Wang, Junkang Zhang, Melina Cavichini, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen, Cheolhong An
    journal: IEEE Access
    year: 2020
    doi: https://doi.org/10.1109/ACCESS.2020.3032348

    # image_bar: /images/bar_TIP2021_robust.png

    abstract: Retinal imaging is crucial in diagnosing and treating retinal diseases, and multimodal retinal image registration constitutes a major advance in understanding retinal diseases. Despite the fact that many methods have been proposed for the registration task, the evaluation metrics for successful registration have not been thoroughly studied. In this article, we present a comprehensive overview of the existing evaluation metrics for multimodal retinal image registration, and compare the similarity between the subjective grade of ophthalmologists and various objective metrics. The Pearson's correlation coefficient and the corresponding confidence interval are used to evaluate metrics similarity. It is found that the binary and soft Dice coefficient on the segmented vessel can achieve the highest correlation with the subjective grades compared to other keypoint-supervised or unsupervised metrics. The paper established an objective metric that is highly correlated with the subjective evaluation of the ophthalmologists, which has never been studied before. The experimental results would build a connection between ophthalmology and image processing literature, and the findings may provide a good insight for researchers who investigate retinal image registration, retinal image segmentation and image domain transformation.


  -
    cite: 2020ICASSP_wang_robust
    type: engineering
    topic: retinal_alignment
    title: A segmentation based robust deep learning framework for multimodal retinal image registration
    authors: Yiqian Wang, Junkang Zhang, Cheolhong An, Melina Cavichini, Mahima Jhingan, Manuel J. Amador-Patarroyo, Christopher P. Long, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen
    conference: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
    year: 2020
    doi: https://doi.org/10.1109/ICASSP40776.2020.9054077

    image_bar: /images/bar_ICASSP2020_robust.png

    abstract: Multimodal image registration plays an important role in diagnosing and treating ophthalmologic diseases. In this paper, a deep learning framework for multimodal retinal image registration is proposed. The framework consists of a segmentation network, feature detection and description network, and an outlier rejection network, which focuses only on the globally coarse alignment step using the perspective transformation. We apply the proposed framework to register color fundus images with infrared reflectance images and compare it with the state-of-the-art conventional and learning-based approaches. The proposed framework demonstrates a significant improvement in robustness and accuracy reflected by a higher success rate and Dice coefficient compared to other coarse alignment methods.

  -
    cite: 2021EMBC_zhang_distortion
    type: engineering
    topic: retinal_alignment
    title: Perspective Distortion Correction for Multi-Modal Registration between Ultra-Widefield and Narrow-Angle Retinal Images
    authors: Junkang Zhang, Yiqian Wang, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen, Cheolhong An
    conference: Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)
    year: 2021
    doi: https://doi.org/10.1109/EMBC46164.2021.9631084

    image_bar: /images/bar_EMBC2021_dc.png

    abstract: Multi-modal retinal image registration between 2D Ultra-Widefield (UWF) and narrow-angle (NA) images has not been well-studied, since most existing methods mainly focus on NA image alignment. The stereographic projection model used in UWF imaging causes strong distortions in peripheral areas, which leads to inferior alignment quality. We propose a distortion correction method that remaps the UWF images based on estimated camera view points of NA images. In addition, we set up a CNN-based registration pipeline for UWF and NA images, which consists of the distortion correction method and three networks for vessel segmentation, feature detection and matching, and outlier rejection. Experimental results on our collected dataset shows the effectiveness of the proposed pipeline and the distortion correction method.

  -
    cite: 2019ICIP_zhang_style
    type: engineering
    topic: retinal_alignment
    title: Joint vessel segmentation and deformable registration on multi-modal retinal images based on style transfer
    authors: Junkang Zhang, Cheolhong An, Ji Dai, Manuel Amador, Dirk-Uwe Bartsch, Shyamanga Borooah, William R. Freeman, Truong Q. Nguyen
    conference: IEEE International Conference on Image Processing (ICIP)
    year: 2019
    doi: https://doi.org/10.1109/ICIP.2019.8802932

    image_bar: /images/bar_ICIP2019_style.png

    code: https://github.com/JunkangZhang/RetinalSegReg
    supplementary: https://github.com/JunkangZhang/RetinalSegReg/blob/master/ICIP2019_supplementary.pdf

    abstract: In multi-modal retinal image registration task, there are two major challenges, i.e., poor performance in finding correspondence due to inconsistent features, and lack of labeled data for training learning-based models. In this paper, we propose a joint vessel segmentation and deformable registration model based on CNN for this task, built under the framework of weakly supervised style transfer learning and perceptual loss. In vessel segmentation, a style loss guides the model to generate segmentation maps that look authentic, and helps transform images of different modalities into consistent representations. In deformable registration, a content loss helps find dense correspondence for multi-modal images based on their consistent representations, and improves the segmentation results simultaneously. Experiment results show that our model has better performance than other deformable registration methods in both quantitative and visual evaluations, and the segmentation results also help the rigid transformation.



  -
    cite: 2020TVST_cavichini_aioverlay
    type: clinical
    topic: retinal_alignment
    title: Artificial Intelligence for Automated Overlay of Fundus Camera and Scanning Laser Ophthalmoscope Images
    authors: Melina Cavichini, Cheolhong An, Dirk-Uwe G. Bartsch, Mahima Jhingan, Manuel J. Amador-Patarroyo, Christopher P. Long, Junkang Zhang, Yiqian Wang, Alison X. Chan, Samantha Madala, Truong Nguyen, William R. Freeman
    journal: Translational Vision Science & Technology
    year: 2020
    doi: https://doi.org/10.1167/tvst.9.2.56

    # image_bar: /images/bar_TIP2022_selfsupervise.png

    abstract: The purpose of this study was to evaluate the ability to align two types of retinal images taken on different platforms; color fundus (CF) photographs and infrared scanning laser ophthalmoscope (IR SLO) images using mathematical warping and artificial intelligence (AI).    We collected 109 matched pairs of CF and IR SLO images. An AI algorithm utilizing two separate networks was developed. A style transfer network (STN) was used to segment vessel structures. A registration network was used to align the segmented images to each. Neither network used a ground truth dataset. A conventional image warping algorithm was used as a control. Software displayed image pairs as a 5 × 5 checkerboard grid composed of alternating subimages. This technique permitted vessel alignment determination by human observers and 5 masked graders evaluated alignment by the AI and conventional warping in 25 fields for each image.    Our new AI method was superior to conventional warping at generating vessel alignment as judged by masked human graders (P \\&lt; 0.0001). The average number of good/excellent matches increased from 90.5\\% to 94.4\\% with AI method.    AI permitted a more accurate overlay of CF and IR SLO images than conventional mathematical warping. This is a first step toward developing an AI that could allow overlay of all types of fundus images by utilizing vascular landmarks.    The ability to align and overlay imaging data from multiple instruments and manufacturers will permit better analysis of this complex data helping understand disease and predict treatment.



  -
    cite: 2022
    type: clinical
    topic: oct
    title: Quantitative evaluation of morphological changes in anti-VEGF treated choroidal neovascularization due to age related macular degeneration using optical coherence tomography angiography
    authors: Anna Heinke, William R. Freeman, Dirk-Uwe G. Bartsch, Lingyun Cheng, Carlo Miguel B. Galang, Alexandra Warter, Fritz Kalaw, Haochen Zhang, Truong Q. Nguyen, Cheolhong An
    conference: ARVO Annual Meeting Abstract
    year: 2022
    doi: https://iovs.arvojournals.org/article.aspx?articleid=2779711

    # image_bar: /images/bar_TIP2022_selfsupervise.png

    abstract: The purpose of this study was to determine if clinical response to anti-VEGF intravitreal injection therapy correlated to quantitative changes of CNV area and vascularity in OCTA.    10 eyes of 10 patients (4 males, 6 females, mean age 75,1 y. o) with CNV were enrolled in the study. The inclusion criteria were presence of CNV confirmed with OCT, OCTA and FA in patients with initially active disease. A comprehensive ophthalmological exam was performed and OCTA was performed with Heidelberg Spectralis or Optovue using high resolution scans during the initial disease activity. The follow-up scan was performed after the successful response, i.e. at the presence of major reduction of sub- or intraretinal fluid or disappearance. CNV area was manually delineated and measured using Image J (area of selection in square milimeters). The CNV vascularity was measured using AngioTool by determining area of the vessels and was determined as a percentage of area occupied by vessels inside the explant area. Paired analysis was performed to compare the parameters at baseline and at the follow-up. The images were overlaid using the opencv(CV2) package in Python to look for morphological changes before and after the treatment.    Analysis of vascularity of the lesion showed a decrease from 34% to 23% (p=0.002). The pre-and post-treatment mean CNV area was 74.26 before versus 66.57 square milimeters after treatment (p=0.1621). The analysis of overlaid images showed that in most cases morphology of the vessels changes with narrowing of the vessels and fewer vessels after the injection.    We found that the CNV vessel percentage area correlates with clinical response to anti-VEGF, and it decreases significantly after the successful treatment. Treatment effect may thus be due to reduced lumen and permeability. The reduction in vascular percentage may be due to reduction in vascular lumen and number of vessels. OCTA thanks to its ability to image the dynamics of neovascular changes may be a useful additional method in determining the optimal intervals of anti-VEGF injection.  This abstract was presented at the 2022 ARVO Annual Meeting, held in Denver, CO, May 1-4, 2022, and virtually.

  -
    cite: 2022
    type: clinical
    topic: retinal_alignment
    title: Comparison of Heidelberg Composite Images with Optos Ultra-Wide Field Images by Overlay using Artificial Intelligence vs Mathematical Warping
    authors: Fritz Gerald Paguiligan Kalaw, Melina Cavichini, Junkang Zhang, Dirk-Uwe G. Bartsch, Varsha Alex, Carlo B. Galang, Anna Heinke, Alexandra Warter, Truong Q. Nguyen, Cheolhong An, William R. Freeman
    conference: ARVO Annual Meeting Abstract
    year: 2022
    doi: https://iovs.arvojournals.org/article.aspx?articleid=2780599

    # image_bar: /images/bar_TIP2022_selfsupervise.png

    abstract: Wide angle imaging is an increasingly important area of retinal research as imaging the retinal periphery may aid in diagnosis of various retinopathies. This is currently being done easily with the Optos machine or, with little difficulty, using overlapping 55-degree scans across the fundus with the Heidelberg system. We aimed to determine if we could overlay images from these two imaging modalities to evaluate abnormalities seen on either machine. We evaluated and compared image alignment using mathematical warping of the images for comparison to Artificial Intelligence-assisted alignment as our group previously described with posterior pole imaging.    A total of 58 eyes were included in the study. Imaging was done on the same day. Single Optos image and 9 images of standard 55-degree fields were captured from multiple views using the Heidelberg machine.Optos image was designated as a reference (i.e. fixed image) during alignment and each of the 9 Heidelberg images were aligned onto the reference. We assumed that both images were captured over a standard 3D spherical eyeball and the Optos camera has a fixed view with regards to the globe, as specified in DICOM standard. Therefore, we set up 3D keypoint coordinates for the Optos image and then estimated a 3D-to-2D (or vice versa) Direct Linear Transformation (DLT) matrix to warp the Heidelberg image.Dice metric based on anatomical structures is adopted as the measurement to evaluate alignment quality. Retinal vessel maps were extracted from both images using third party segmentation algorithms. The Dice value was calculated over the vessel maps. Image masks indicating imaging circles are also applied to limit the computation in the overlapping areas between both images.    Twenty-four eyes are currently being studied with a total of 240 images (10 image per eye). Four out of the 24 resulting composite images contain exaggerated patterns due to distortions which cannot be solved by the DLT method and manual labels, which are therefore excluded from the alignment evaluation. The average Dice values for the remaining 20 image pairs is 0.4652.    Ultra-wide angle from different instruments can be co-localized and this may permit better evaluation of abnormalities seen on the two instruments. AI-enhancement of mathematical warping is ongoing and will be presented in the final paper.  This abstract was presented at the 2022 ARVO Annual Meeting, held in Denver, CO, May 1-4, 2022, and virtually.
