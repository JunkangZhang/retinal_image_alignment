papers:
  -
    cite: 2022TIP_an_selfsupervise
    topic: retinal_alignment
    title: Self-Supervised Rigid Registration for Multimodal Retinal Images
    authors: Cheolhong An, Yiqian Wang, Junkang Zhang, Truong Q Nguyen
    journal: IEEE Transactions on Image Processing
    abstract: abstract placeholder
    year: 2022
    doi: https://doi.org/10.1109/TIP.2022.3201476

    image_bar: /images/bar_TIP2022_selfsupervise.png

    abstract: The ability to accurately overlay one modality retinal image to another is critical in ophthalmology. Our previous framework achieved the state-of-the-art results for multimodal retinal image registration. However, it requires human-annotated labels due to the supervised approach of the previous work. In this paper, we propose a self-supervised multimodal retina registration method to alleviate the burdens of time and expense to prepare for training data, that is, aiming to automatically register multimodal retinal images without any human annotations. Specially, we focus on registering color fundus images with infrared reflectance and fluorescein angiography images, and compare registration results with several conventional and supervised and unsupervised deep learning methods. From the experimental results, the proposed self-supervised framework achieves a comparable accuracy comparing to the state-of-the-art supervised learning method in terms of registration accuracy and Dice coefficient.

  -
    cite: 2022TIP_zhang_twostep
    topic: retinal_alignment
    title: Two-Step Registration on Multi-Modal Retinal Images via Deep Neural Networks
    authors: Junkang Zhang, Yiqian Wang, Ji Dai, Melina Cavichini, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen, Cheolhong An
    journal: IEEE Transactions on Image Processing
    abstract: abstract placeholder
    year: 2022
    doi: https://doi.org/10.1109/TIP.2021.3135708

    image_bar: /images/bar_TIP2022_twostep.png

    abstract: Multi-modal retinal image registration plays an important role in the ophthalmological diagnosis process. The conventional methods lack robustness in aligning multi-modal images of various imaging qualities. Deep-learning methods have not been widely developed for this task, especially for the coarse-to-fine registration pipeline. To handle this task, we propose a two-step method based on deep convolutional networks, including a coarse alignment step and a fine alignment step. In the coarse alignment step, a global registration matrix is estimated by three sequentially connected networks for vessel segmentation, feature detection and description, and outlier rejection, respectively. In the fine alignment step, a deformable registration network is set up to find pixel-wise correspondence between a target image and a coarsely aligned image from the previous step to further improve the alignment accuracy. Particularly, an unsupervised learning framework is proposed to handle the difficulties of inconsistent modalities and lack of labeled training data for the fine alignment step. The proposed framework first changes multi-modal images into a same modality through modality transformers, and then adopts photometric consistency loss and smoothness loss to train the deformable registration network. The experimental results show that the proposed method achieves state-of-the-art results in Dice metrics and is more robust in challenging cases.

  -
    cite: 2021TIP_wang_robust
    topic: retinal_alignment
    title: Robust content-adaptive global registration for multimodal retinal images using weakly supervised deep-learning framework
    authors: Yiqian Wang, Junkang Zhang, Melina Cavichini, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen, Cheolhong An
    journal: IEEE Transactions on Image Processing
    abstract: abstract placeholder
    year: 2021
    doi: https://doi.org/10.1109/TIP.2021.3058570

    image_bar: /images/bar_TIP2021_robust.png

    abstract: Multimodal retinal imaging plays an important role in ophthalmology. We propose a content-adaptive multimodal retinal image registration method in this paper that focuses on the globally coarse alignment and includes three weakly supervised neural networks for vessel segmentation, feature detection and description, and outlier rejection. We apply the proposed framework to register color fundus images with infrared reflectance and fluorescein angiography images, and compare it with several conventional and deep learning methods. Our proposed framework demonstrates a significant improvement in robustness and accuracy reflected by a higher success rate and Dice coefficient compared with other methods.

  -
    cite: 2020ICASSP_wang_robust
    topic: retinal_alignment
    title: A segmentation based robust deep learning framework for multimodal retinal image registration
    authors: Yiqian Wang, Junkang Zhang, Cheolhong An, Melina Cavichini, Mahima Jhingan, Manuel J. Amador-Patarroyo, Christopher P. Long, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen
    conference: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
    abstract: abstract placeholder
    year: 2020
    doi: https://doi.org/10.1109/ICASSP40776.2020.9054077

    image_bar: /images/bar_ICASSP2020_robust.png

    abstract: Multimodal image registration plays an important role in diagnosing and treating ophthalmologic diseases. In this paper, a deep learning framework for multimodal retinal image registration is proposed. The framework consists of a segmentation network, feature detection and description network, and an outlier rejection network, which focuses only on the globally coarse alignment step using the perspective transformation. We apply the proposed framework to register color fundus images with infrared reflectance images and compare it with the state-of-the-art conventional and learning-based approaches. The proposed framework demonstrates a significant improvement in robustness and accuracy reflected by a higher success rate and Dice coefficient compared to other coarse alignment methods.

  -
    cite: 2021EMBC_zhang_distortion
    topic: retinal_alignment
    title: Perspective Distortion Correction for Multi-Modal Registration between Ultra-Widefield and Narrow-Angle Retinal Images
    authors: Junkang Zhang, Yiqian Wang, Dirk-Uwe G. Bartsch, William R. Freeman, Truong Q. Nguyen, Cheolhong An
    conference: Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)
    abstract: abstract placeholder
    year: 2021
    doi: https://doi.org/10.1109/EMBC46164.2021.9631084

    image_bar: /images/bar_EMBC2021_dc.png

    abstract: Multi-modal retinal image registration between 2D Ultra-Widefield (UWF) and narrow-angle (NA) images has not been well-studied, since most existing methods mainly focus on NA image alignment. The stereographic projection model used in UWF imaging causes strong distortions in peripheral areas, which leads to inferior alignment quality. We propose a distortion correction method that remaps the UWF images based on estimated camera view points of NA images. In addition, we set up a CNN-based registration pipeline for UWF and NA images, which consists of the distortion correction method and three networks for vessel segmentation, feature detection and matching, and outlier rejection. Experimental results on our collected dataset shows the effectiveness of the proposed pipeline and the distortion correction method.

  -
    cite: 2019ICIP_zhang_style
    topic: retinal_alignment
    title: Joint vessel segmentation and deformable registration on multi-modal retinal images based on style transfer
    authors: Junkang Zhang, Cheolhong An, Ji Dai, Manuel Amador, Dirk-Uwe Bartsch, Shyamanga Borooah, William R. Freeman, Truong Q. Nguyen
    conference: IEEE International Conference on Image Processing (ICIP)
    abstract: abstract placeholder
    year: 2019
    doi: https://doi.org/10.1109/ICIP.2019.8802932

    image_bar: /images/bar_ICIP2019_style.png

    code: https://github.com/JunkangZhang/RetinalSegReg
    supplementary: https://github.com/JunkangZhang/RetinalSegReg/blob/master/ICIP2019_supplementary.pdf

    abstract: In multi-modal retinal image registration task, there are two major challenges, i.e., poor performance in finding correspondence due to inconsistent features, and lack of labeled data for training learning-based models. In this paper, we propose a joint vessel segmentation and deformable registration model based on CNN for this task, built under the framework of weakly supervised style transfer learning and perceptual loss. In vessel segmentation, a style loss guides the model to generate segmentation maps that look authentic, and helps transform images of different modalities into consistent representations. In deformable registration, a content loss helps find dense correspondence for multi-modal images based on their consistent representations, and improves the segmentation results simultaneously. Experiment results show that our model has better performance than other deformable registration methods in both quantitative and visual evaluations, and the segmentation results also help the rigid transformation.
